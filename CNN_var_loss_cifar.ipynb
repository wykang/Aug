{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys \n",
    "import numpy as np\n",
    "import h5py \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import control_flow_ops\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''Convert class labels from scalars to one-hot vectors.'''\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes), dtype=np.float32)\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: [u't_test', u't_train', u't_valid', u'x_test', u'x_train', u'x_valid']\n"
     ]
    }
   ],
   "source": [
    "## for minist\n",
    "hf = h5py.File('../data/mnist.hdf5','r')\n",
    "print('datasets: {}'.format(hf.keys()))\n",
    "\n",
    "n_class     = 10\n",
    "width_size  = 28\n",
    "height_size = 28\n",
    "area_size   = width_size * height_size\n",
    "\n",
    "trainingSize = hf['x_train'].shape[0]\n",
    "validationSize = hf['x_valid'].shape[0]\n",
    "testSize = hf['x_test'].shape[0]\n",
    "\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: [u'test_set_x', u'test_set_y', u'train_set_x', u'train_set_y', u'valid_set_x', u'valid_set_y']\n",
      "40000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('../data/cifar-10.hdf5','r')\n",
    "print('datasets: {}'.format(hf.keys()))\n",
    "\n",
    "#x_train = theano.shared(hf['x_train'][()])\n",
    "#t_train = theano.shared(dense_to_one_hot(np.array(hf['t_train'][()])))\n",
    "#x_valid = theano.shared(hf['x_valid'][()])\n",
    "#t_valid = theano.shared(dense_to_one_hot(np.array(hf['t_valid'][()])))\n",
    "#x_test  = theano.shared(hf['x_test'][()])\n",
    "#t_test  = theano.shared(dense_to_one_hot(np.array(hf['t_test'][()])))\n",
    "\n",
    "n_class     = 10\n",
    "width_size  = 32\n",
    "height_size = 32\n",
    "area_size   = width_size * height_size * 3\n",
    "trainingSize = hf['train_set_x'].shape[0]\n",
    "validationSize = hf['valid_set_x'].shape[0]\n",
    "testSize = hf['test_set_x'].shape[0]\n",
    "\n",
    "print trainingSize, validationSize, testSize\n",
    "\n",
    "batch_size = 200\n",
    "C_val = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[size of each set]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (Object 'train_set_x' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-19a1858ceea9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'[size of each set]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'training_set : %d, valid_set : %d, test_set : %d'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_set_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid_set_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_set_x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'[size of each batch]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'training_set : %d, valid_set : %d, test_set : %d'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_valid_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_test_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/h5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2691)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mneeded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0macquires\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnotifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mall\u001b[0m \u001b[0mmade\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mwonderful\u001b[0m \u001b[0mGIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m     56\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mpythread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyThread_type_lock\u001b[0m \u001b[0m_real_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/h5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2649)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mall\u001b[0m \u001b[0mmade\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mwonderful\u001b[0m \u001b[0mGIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \"\"\"\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mpythread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyThread_type_lock\u001b[0m \u001b[0m_real_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mlong\u001b[0m \u001b[0m_owner\u001b[0m            \u001b[1;31m# ID of thread owning the lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/h5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2691)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mneeded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0macquires\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnotifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0mthread\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mall\u001b[0m \u001b[0mmade\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mwonderful\u001b[0m \u001b[0mGIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \"\"\"\n\u001b[0;32m     56\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mpythread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyThread_type_lock\u001b[0m \u001b[0m_real_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/h5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2649)\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mall\u001b[0m \u001b[0mmade\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mwonderful\u001b[0m \u001b[0mGIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \"\"\"\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mpythread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyThread_type_lock\u001b[0m \u001b[0m_real_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mlong\u001b[0m \u001b[0m_owner\u001b[0m            \u001b[1;31m# ID of thread owning the lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/dist-packages/h5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open (/tmp/pip_build_root/h5py/h5py/h5o.c:3577)\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m     char* dst_name, PropID copypl=None, PropID lcpl=None):\n\u001b[0;32m    189\u001b[0m     \"\"\"(ObjectID src_loc, STRING src_name, GroupID dst_loc, STRING dst_name,\n\u001b[1;32m--> 190\u001b[1;33m     PropID copypl=None, PropID lcpl=None)\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mCopy\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnamed\u001b[0m \u001b[0mdatatype\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mone\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0mto\u001b[0m \u001b[0manother\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mThe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (Object 'train_set_x' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "datasets = load_data(dataset)\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\"\"\"\n",
    "# compute number of minibatches for training, validation and testing\n",
    "batch_size = 200\n",
    "n_train_batches = trainingSize\n",
    "n_valid_batches = validationSize\n",
    "n_test_batches = testSize\n",
    "n_train_batches /= batch_size\n",
    "n_valid_batches /= batch_size\n",
    "n_test_batches /= batch_size\n",
    "\n",
    "print '[size of each set]'\n",
    "print ('training_set : %d, valid_set : %d, test_set : %d' %(hf['train_set_x'].shape[0], hf['valid_set_x'].shape[0], hf['test_set_x'].shape[0]))\n",
    "print '[size of each batch]'\n",
    "print ('training_set : %d, valid_set : %d, test_set : %d' %(n_train_batches, n_valid_batches, n_test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_n_param = [3, 3, 3, 32]\n",
    "poo11_n_param = (2, 2)\n",
    "conv2_n_param = [3, 3, 32, 64]\n",
    "pool2_n_param = (2, 2)\n",
    "\n",
    "conv3_n_param = [5, 5, 64, 128]\n",
    "pool3_n_param = (2, 2)\n",
    "conv4_n_param = [3, 3, 128, 64]\n",
    "pool4_n_param = (4, 4)\n",
    "\n",
    "fc1_n_param = [1 * 1 * 64, 2]\n",
    "fc2_n_param = [2, n_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_moments(x, mode):\n",
    "    batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(mode,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def var_loss_fc(features, labels, idx, mode):\n",
    "    locs = tf.where(tf.equal(labels, idx))\n",
    "    batch_mean, batch_var = tf.nn.moments(tf.gather(features, locs), [0], name='moments_fc')\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n",
    "    def mean_var_with_update():\n",
    "                with tf.control_dependencies([ema_apply_op]):\n",
    "                    return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "    mean, var = control_flow_ops.cond(mode,\n",
    "        mean_var_with_update,\n",
    "        lambda: (ema_mean, ema_var))\n",
    "    return mean, var\n",
    "    #intra_loss = tf.reduce_sum(intra_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def var_loss_cnn(features, labels, idx):\n",
    "    locs = tf.where(tf.equal(labels, idx))\n",
    "    intra_mean, intra_var = tf.nn.moments(tf.gather(features, locs), [0,1], name='moments_cnn')\n",
    "    #intra_loss = tf.reduce_sum(intra_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clac_layerwise_loss(moments, size):\n",
    "    var_list = []\n",
    "    for i in range (0, n_class):\n",
    "        var_list.append(moments[i][1])\n",
    "    packed_intra = tf.pack(var_list)  \n",
    "    packed_intra = tf.reshape(packed_intra, [n_class, size])\n",
    "    #print packed_intra.get_shape()\n",
    "    intra_var_loss = tf.reduce_sum(packed_intra)\n",
    "    #print hid_layer_1_losses.get_shape()\n",
    "    #print moments[0][0]\n",
    "    #print moments[0][0].get_shape()\n",
    "    mean_list = []\n",
    "    for i in range (0, n_class):\n",
    "        mean_list.append(moments[i][0])\n",
    "    packed = tf.pack(mean_list)\n",
    "    packed = tf.reshape(packed, [n_class, size])\n",
    "    packed_mean, packed_var = tf.nn.moments(packed, [0], name = 'moments_fc_total')\n",
    "    #print packed_var.get_shape()\n",
    "    inter_var_loss = tf.reduce_sum(packed_var)\n",
    "    layer_loss = intra_var_loss / inter_var_loss\n",
    "    return layer_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", shape=[None, 32, 32, 3])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, n_class])\n",
    "y_scalar = tf.placeholder(\"float\", shape=[None])\n",
    "dummy_bool = tf.placeholder(tf.bool, name='phase_train')\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.02)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.02, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, stride):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, stride, stride, 1], padding='SAME')\n",
    "def max_pool_4x4(x, stride):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 4, 4, 1],\n",
    "                        strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "#x_ = tf.reshape(x, [-1, 32, 32, 1])\n",
    "W_conv1 = weight_variable(conv1_n_param)\n",
    "b_conv1 = bias_variable([conv1_n_param[-1]])\n",
    "feature_ly1 = conv2d(x, W_conv1, 1) + b_conv1\n",
    "moments_cv1 = [var_loss_fc(feature_ly1, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "cv1_loss = clac_layerwise_loss(moments_cv1, conv1_n_param[-1] *32 * 32)\n",
    "h_conv1 = tf.nn.relu(feature_ly1)\n",
    "h_pool1 = max_pool_2x2(h_conv1, 2)\n",
    "\n",
    "W_conv2 = weight_variable(conv2_n_param)\n",
    "b_conv2 = bias_variable([conv2_n_param[-1]])\n",
    "feature_ly2 = conv2d(h_pool1, W_conv2, 1) + b_conv2\n",
    "moments_cv2 = [var_loss_fc(feature_ly2, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "cv2_loss = clac_layerwise_loss(moments_cv2, conv2_n_param[-1] *16 * 16)\n",
    "h_conv2 = tf.nn.relu(feature_ly2)\n",
    "h_pool2 = max_pool_2x2(h_conv2, 2)\n",
    "\n",
    "W_conv3 = weight_variable(conv3_n_param)\n",
    "b_conv3 = bias_variable([conv3_n_param[-1]])\n",
    "feature_ly3 = conv2d(h_pool2, W_conv3, 1) + b_conv3\n",
    "moments_cv3 = [var_loss_fc(feature_ly3, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "cv3_loss = clac_layerwise_loss(moments_cv3, conv3_n_param[-1] *8 * 8)\n",
    "h_conv3 = tf.nn.relu(feature_ly3)\n",
    "h_pool3 = max_pool_2x2(h_conv3, 2)\n",
    "\n",
    "W_conv4 = weight_variable(conv4_n_param)\n",
    "b_conv4 = bias_variable([conv4_n_param[-1]])\n",
    "feature_ly4 = conv2d(h_pool3, W_conv4, 1) + b_conv4\n",
    "h_conv4 = tf.nn.relu(feature_ly4)\n",
    "moments_cv4 = [var_loss_fc(feature_ly4, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "cv4_loss = clac_layerwise_loss(moments_cv4, conv4_n_param[-1] * 4 * 4)\n",
    "h_pool4 = max_pool_4x4(h_conv4, 1)\n",
    "#print h_pool4.get_shape()[3]\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4, [-1, fc1_n_param[0]])\n",
    "\n",
    "W_fc1 = weight_variable(fc1_n_param)\n",
    "b_fc1 = bias_variable([fc1_n_param[-1]])\n",
    "w_sum_fc1 = tf.matmul(h_pool4_flat, W_fc1) + b_fc1\n",
    "moments_fc1 = [var_loss_fc(w_sum_fc1, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "fc1_loss = clac_layerwise_loss(moments_fc1, fc1_n_param[-1])\n",
    "h_fc1 = tf.nn.relu(w_sum_fc1)\n",
    "locs = [tf.where(tf.equal(y_scalar, idx)) for idx in range(0, n_class)]\n",
    "\n",
    "W_fc2 = weight_variable(fc2_n_param)\n",
    "b_fc2 = bias_variable([fc2_n_param[-1]])\n",
    "w_sum_fc2 = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "moments_fc2 = [var_loss_fc(w_sum_fc2, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "fc2_loss = clac_layerwise_loss(moments_fc2, fc2_n_param[-1])\n",
    "h_fc2 = tf.nn.relu(w_sum_fc2)\n",
    "output = tf.nn.softmax(h_fc2)\n",
    "'''\n",
    "w_sum_fc1 = tf.matmul(flat_x, W_fc1) + b_fc1\n",
    "moments_fc1 = [var_loss_fc(w_sum_fc1, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "fc1_loss = clac_layerwise_loss(moments_fc1, fc1_n_param[-1])\n",
    "hid_layer_1 = tf.nn.relu(w_sum_fc1)\n",
    "\n",
    "\n",
    "#moment_mean, moment_var = tf.nn.moments(mean_list, [0], name='moments_fc_total')\n",
    "#print moment_mean.get_shape()\n",
    "\n",
    "W_fc2 = weight_variable(fc2_n_param)\n",
    "b_fc2 = bias_variable([fc2_n_param[-1]])\n",
    "w_sum_fc2 = tf.matmul(hid_layer_1, W_fc2) + b_fc2\n",
    "moments_fc2 = [var_loss_fc(w_sum_fc2, y_scalar, idx, dummy_bool) for idx in range(0, n_class)]\n",
    "fc2_loss = clac_layerwise_loss(moments_fc2, fc2_n_param[-1])\n",
    "hid_layer_2 = tf.nn.softmax(w_sum_fc2)\n",
    "\n",
    "\n",
    "W_fc3 = weight_variable(fc3_n_param)\n",
    "b_fc3 = bias_variable([fc3_n_param[-1]])\n",
    "hid_layer_3 = tf.nn.softmax(tf.matmul(hid_layer_2, W_fc3) + b_fc3)\n",
    "'''\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(tf.clip_by_value(output, 1e-10, 1.0))) #loss는 최종 loss + 각 레이어의 var정보\n",
    "loss = cross_entropy #+ cv4_loss ##+ fc2_loss + fc1_loss + cv2_loss + cv1_loss + cv3_loss + cv4_loss\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize( cross_entropy)#\n",
    "#print y_*tf.log(tf.clip_by_value(hid_layer_3,1e-10,1.0)).get_shape()\n",
    "correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "#batch_mean, batch_var = tf.reduce_mean(tf.gather(x, locs), 0)\n",
    "#batch_mean, batch_var = tf.nn.moments(tf.gather(x, locs), [0], name='moments')\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_Idx = 0\n",
    "end_Idx = 300\n",
    "\n",
    "x_train = np.array(hf['train_set_x'][start_Idx:end_Idx])\n",
    "y_train = dense_to_one_hot(np.array(hf['train_set_y'][start_Idx:end_Idx]))\n",
    "y_train_s = np.array(hf['train_set_y'][start_Idx:end_Idx])\n",
    "#x_train = np.array(hf['x_train'][start_Idx:end_Idx]).reshape(300,28,28,1)\n",
    "#y_train = dense_to_one_hot(np.array(hf['t_train'][start_Idx:end_Idx]))\n",
    "#y_train_s = np.array(hf['t_train'][start_Idx:end_Idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locIdx = []\n",
    "for idx in range(0, n_class):\n",
    "    locIdx.append(locs[idx].eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.01781\n",
      "0.223333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEACAYAAABLfPrqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fefa3f97610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx in range(0, 300):\n",
    "    train_step.run(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "\n",
    "#print W_fc1.eval()\n",
    "print fc1_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "print accuracy.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "#print moments_fc1[0][1].eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "\n",
    "##plot\n",
    "\n",
    "res = w_sum_fc1.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(locIdx)))\n",
    "plts = []\n",
    "for idx in range(0, n_class):\n",
    "    plts.append(plt.scatter(res[locIdx[idx],0],res[locIdx[idx],1],color=colors[idx]))\n",
    "    \n",
    "plt.legend((plts[0], plts[1], plts[2], plts[3], plts[4], plts[5], plts[6], plts[7], plts[8], plts[9]),\n",
    "       ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'),\n",
    "       scatterpoints=1,\n",
    "       loc='upper right',\n",
    "       ncol=3,\n",
    "       fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_dir = datetime.datetime.now().isoformat() + '_var_loss_CNN_cifar10_color_test_cross_cv4loss'\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_train_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-90b3459acc0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpatience\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m  \u001b[1;31m# look as this many examples regardless\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mvalidation_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mepoch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcol_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marea_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_train_batches' is not defined"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# TRAIN MODEL #\n",
    "###############\n",
    "\n",
    "t_next = time.time()\n",
    "t_prev = time.time()\n",
    "\n",
    "patience = 10000  # look as this many examples regardless\n",
    "validation_frequency = min(n_train_batches, patience / 2)\n",
    "epoch_size = 50\n",
    "col_count = area_size\n",
    "startIdx = 0\n",
    "endIdx = batch_size\n",
    "k = 0\n",
    "\n",
    "accuracy_train = 0\n",
    "valid_accuracy = 0\n",
    "test_accuracy = 0\n",
    "while (k <= epoch_size):\n",
    "    k = k + 1\n",
    "    start_Idx = 0\n",
    "    end_Idx = batch_size\n",
    "    accuracy_train = 0\n",
    "    for minibatch_index in xrange(n_train_batches): #per epoch\n",
    "        iter = (k - 1) * n_train_batches + minibatch_index\n",
    "        x_train = np.array(hf['train_set_x'][start_Idx:end_Idx])\n",
    "        x_train = np.rollaxis(x_train,1,4)\n",
    "        #print x_train.shape\n",
    "        y_train_s = np.array(hf['train_set_y'][start_Idx:end_Idx])\n",
    "        y_train = dense_to_one_hot(y_train_s)\n",
    "        \n",
    "        start_Idx = end_Idx\n",
    "        end_Idx = end_Idx + batch_size\n",
    "        train_step.run(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "        accuracy_train = accuracy_train + accuracy.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "        #accuracy_train /= minibatch_index + 1\n",
    "        if end_Idx % 10000 == 0:            \n",
    "            print('%d/%d epoch, @iter = %d/%d, training accuracy : %.5f' %(k, epoch_size, end_Idx, trainingSize, accuracy_train/(minibatch_index + 1)))\n",
    "        \n",
    "        if (iter + 1) % validation_frequency == 0:\n",
    "            loss_fc1 = fc1_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "            loss_cv1 = cv1_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "            loss_cv2 = cv2_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "            loss_cv3 = cv3_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "            loss_cv4 = cv4_loss.eval(feed_dict={x: x_train, y_: y_train, y_scalar: y_train_s, dummy_bool: False})\n",
    "            \n",
    "            print('<<<<<epoch %i, minibatch %i/%i, training accuracy %.5f, cv1 %.2f, cv2 %.2f, cv3 %.2f, cv4 %.2f, fc1 %.2f>>>>>' %\n",
    "                  (k, minibatch_index + 1, n_train_batches,\n",
    "                   accuracy_train/(minibatch_index + 1), loss_cv1, loss_cv2, loss_cv3, loss_cv4, loss_fc1))\n",
    "            # compute zero-one loss on validation set\n",
    "            start_Idx_valid = 0\n",
    "            end_Idx_valid = batch_size\n",
    "            valid_loss = 0;\n",
    "            valid_accuracy = 0\n",
    "            for valid_minibatch in xrange(n_valid_batches):\n",
    "                x_valid = np.array(hf['valid_set_x'][start_Idx_valid:end_Idx_valid])\n",
    "                x_valid = np.rollaxis(x_valid,1,4)\n",
    "                y_valid_s = np.array(hf['valid_set_y'][start_Idx_valid:end_Idx_valid])\n",
    "                y_valid = dense_to_one_hot(y_valid_s)\n",
    "                start_Idx_valid  = end_Idx_valid\n",
    "                end_Idx_valid = end_Idx_valid + batch_size               \n",
    "                valid_accuracy = valid_accuracy + accuracy.eval(feed_dict={x: x_valid, y_: y_valid, y_scalar: y_valid_s, dummy_bool: False})\n",
    "\n",
    "            valid_accuracy = valid_accuracy / n_valid_batches\n",
    "            print('epoch %i, minibatch %i/%i, valid accuracy %.5f' %\n",
    "                  (k, minibatch_index + 1, n_train_batches, valid_accuracy))\n",
    "\n",
    "            # test it on the test set\n",
    "            start_Idx_test = 0\n",
    "            end_Idx_test = batch_size\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            for test_minibatch in xrange(n_test_batches):\n",
    "                x_test = np.array(hf['test_set_x'][start_Idx_test:end_Idx_test])\n",
    "                x_test = np.rollaxis(x_test,1,4)\n",
    "                y_test_s = np.array(hf['test_set_y'][start_Idx_test:end_Idx_test])\n",
    "                y_test= dense_to_one_hot(y_test_s)\n",
    "                start_Idx_test  = end_Idx_test\n",
    "                end_Idx_test= end_Idx_test + batch_size\n",
    "                test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: x_test, y_: y_test, y_scalar: y_test_s, dummy_bool: False})\n",
    "\n",
    "            test_score = test_loss / n_test_batches\n",
    "            test_accuracy = test_accuracy / n_test_batches\n",
    "            print('     epoch %i, minibatch %i/%i, test accuracy %.5f' %\n",
    "                      (k, minibatch_index + 1, n_train_batches, test_accuracy))\n",
    "            \n",
    "            f = open(res_dir + '/status_training.txt', 'a')\n",
    "            f.write(\"epoch %d, training accuracy %.5f, valid accuracy : %.5f, test accuracy: %.5f, cv1 %.2f, cv2 %.2f, cv3 %.2f, cv4 %.2f, fc1 %.2f\\n\"%(k, \n",
    "                        accuracy_train/(minibatch_index + 1), valid_accuracy, test_accuracy, loss_cv1, loss_cv2, loss_cv3, loss_cv4, loss_fc1))\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
